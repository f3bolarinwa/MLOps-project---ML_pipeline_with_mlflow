diff --git a/conda.yml b/conda.yml
index 220ec0b..c1a5b27 100644
--- a/conda.yml
+++ b/conda.yml
@@ -3,7 +3,7 @@ channels:
   - conda-forge
   - defaults
 dependencies:
-  - mlflow=1.14.1
+  - mlflow=2.2.2
   - pyyaml=5.3.1
   - hydra-core=1.0.6
   - pip=20.3.3
diff --git a/environment.yml b/environment.yml
index efabac5..a507535 100644
--- a/environment.yml
+++ b/environment.yml
@@ -3,7 +3,7 @@ channels:
   - conda-forge
   - defaults
 dependencies:
-  - mlflow=1.14.1
+  - mlflow=2.2.2
   - ipython=7.21.0
   - notebook=6.2.0
   - jupyterlab=3.0.10
diff --git a/main.py b/main.py
index 27a89b1..83ccb51 100644
--- a/main.py
+++ b/main.py
@@ -1,5 +1,13 @@
-import json
+'''
+This module contains code to run the entire ML pipeline
+or a single component of the pipeline at a time using MLflow
+
+Author: Femi Bolarinwa
+Date: August 2023
+'''
 
+#importing libraries
+import json
 import mlflow
 import tempfile
 import os
@@ -7,24 +15,25 @@ import wandb
 import hydra
 from omegaconf import DictConfig
 
+#components of the ML pipeline
 _steps = [
     "download",
     "basic_cleaning",
     "data_check",
     "data_split",
     "train_random_forest",
-    # NOTE: We do not include this in the steps so it is not run by mistake.
-    # You first need to promote a model export to "prod" before you can run this,
-    # then you need to run this step explicitly
-#    "test_regression_model"
+    # NOTE: I do not include "test_regression_model" pipeline component in the
+    #steps so it is not run by mistake. You first need to promote a model export
+    #to "prod" in W&B before you can run the component
+      
 ]
 
 
-# This automatically reads in the configuration
+# This enables hydra to read the configuration file
 @hydra.main(config_name='config')
 def go(config: DictConfig):
 
-    # Setup the wandb experiment. All runs will be grouped under this name
+    # Sets up the wandb experiment. All runs will be grouped under this name
     os.environ["WANDB_PROJECT"] = config["main"]["project_name"]
     os.environ["WANDB_RUN_GROUP"] = config["main"]["experiment_name"]
 
@@ -32,11 +41,14 @@ def go(config: DictConfig):
     steps_par = config['main']['steps']
     active_steps = steps_par.split(",") if steps_par != "all" else _steps
 
-    # Move to a temporary directory
+    # Moves to a temporary directory so that no file is left in the local directory
+    #after running ML pipeline or components
+
     with tempfile.TemporaryDirectory() as tmp_dir:
 
         if "download" in active_steps:
-            # Download file and load in W&B
+            # Extracts file from a git repo and load to W&B.
+            # Note that MLflow project environment is defined in the git repo
             _ = mlflow.run(
                 f"{config['main']['components_repository']}/get_data",
                 "main",
@@ -50,47 +62,96 @@ def go(config: DictConfig):
             )
 
         if "basic_cleaning" in active_steps:
-            ##################
-            # Implement here #
-            ##################
-            pass
+            # Performs basic ETL on output of "download" component.
+            # Note that MLflow project environment for this component is defined in the local machine
+
+            _ = mlflow.run(
+                 os.path.join(hydra.utils.get_original_cwd(), "src", "basic_cleaning"),
+                 "main",
+                 parameters={
+                     "input_artifact": "sample.csv:latest",
+                     "output_artifact": "clean_sample.csv",
+                     "output_type": "clean_sample",
+                     "output_description": "Data with outliers and null values removed",
+                     "min_price": config['etl']['min_price'],
+                     "max_price": config['etl']['max_price']
+                 },
+            )
 
         if "data_check" in active_steps:
-            ##################
-            # Implement here #
-            ##################
-            pass
+            # Implement basic data checks and validation using pytest on output of "basic_cleaning" component
+            # Note that MLflow project environment for this component is defined in the local machine
+            _ = mlflow.run(
+                 os.path.join(hydra.utils.get_original_cwd(), "src", "data_check"),
+                 "main",
+                 parameters={
+                     "csv": "clean_sample.csv:latest",
+                     "ref": "clean_sample.csv:reference",
+                     "kl_threshold": config['data_check']['kl_threshold'],
+                     "min_price": config['etl']['min_price'],
+                     "max_price": config['etl']['max_price']
+                 },
+            )
+
+
 
         if "data_split" in active_steps:
-            ##################
-            # Implement here #
-            ##################
-            pass
+            # splits output of "data_check" component to train-test datasets.
+            # Note that MLflow project environment for this component is defined in a git repo
+            _ = mlflow.run(
+                f"{config['main']['components_repository']}/train_val_test_split",
+                "main",
+                version='main',
+                parameters={
+                    "input": "clean_sample.csv:latest",
+                    "test_size": config['modeling']['test_size'],
+                    "random_seed": config['modeling']['random_seed'],
+                    "stratify_by": config['modeling']['stratify_by']
+                },
+            )
+
 
         if "train_random_forest" in active_steps:
+            #component trains a random forest model on train_data from "data_slit" component.
+            # Note that MLflow project environment for this component is defined in the local machine
 
             # NOTE: we need to serialize the random forest configuration into JSON
             rf_config = os.path.abspath("rf_config.json")
             with open(rf_config, "w+") as fp:
-                json.dump(dict(config["modeling"]["random_forest"].items()), fp)  # DO NOT TOUCH
+                json.dump(dict(config["modeling"]["random_forest"].items()), fp) 
 
-            # NOTE: use the rf_config we just created as the rf_config parameter for the train_random_forest
+            # NOTE: i'll use the rf_config we just created as the rf_config parameter for the train_random_forest
             # step
 
-            ##################
-            # Implement here #
-            ##################
-
-            pass
+            _ = mlflow.run(
+            os.path.join(hydra.utils.get_original_cwd(), "src", "train_random_forest"),
+            "main",
+            parameters={
+                "trainval_artifact": "trainval_data.csv:latest",
+                "val_size": config["modeling"]["val_size"],
+                "random_seed": config["modeling"]["random_seed"],
+                "stratify_by": config["modeling"]["stratify_by"],
+                "rf_config": rf_config,
+                "max_tfidf_features": config["modeling"]["max_tfidf_features"],
+                "output_artifact": "random_forest_dir"
 
-        if "test_regression_model" in active_steps:
+            },
+        )
 
-            ##################
-            # Implement here #
-            ##################
 
-            pass
+        if "test_regression_model" in active_steps:
+            #component to test selected model.
+            #i need to promote a model export to "prod" in W&B before running the component.
+            # Note that MLflow project environment for this component is defined in the local machine
 
+            _ = mlflow.run(
+            os.path.join(hydra.utils.get_original_cwd(), "src", "test_regression_model"),
+            "main",
+            parameters={
+                "mlflow_model": "random_forest_dir:prod",
+                "test_dataset": "test_data.csv:latest"
+            }
+        )
 
 if __name__ == "__main__":
     go()
diff --git a/src/data_check/MLproject b/src/data_check/MLproject
index 8874479..b5c928e 100644
--- a/src/data_check/MLproject
+++ b/src/data_check/MLproject
@@ -25,4 +25,8 @@ entry_points:
         description: Maximum accepted price
         type: float
 
-    command: "pytest . -vv --csv {csv} --ref {ref} --kl_threshold {kl_threshold} --min_price {min_price} --max_price {max_price}"
+    command: "pytest . -vv --csv {csv} \
+                           --ref {ref} \
+                           --kl_threshold {kl_threshold} \
+                           --min_price {min_price} \
+                           --max_price {max_price}"
diff --git a/src/data_check/test_data.py b/src/data_check/test_data.py
index 6ed3ec6..45d4079 100644
--- a/src/data_check/test_data.py
+++ b/src/data_check/test_data.py
@@ -63,3 +63,11 @@ def test_similar_neigh_distrib(data: pd.DataFrame, ref_data: pd.DataFrame, kl_th
 ########################################################
 # Implement here test_row_count and test_price_range   #
 ########################################################
+
+def test_row_count(data):
+    assert 15000 < data.shape[0] < 1000000
+
+
+def test_price_range(data, min_price, max_price):
+    idx = data['price'].between(min_price, max_price)
+    assert np.sum(~idx) == 0
diff --git a/src/eda/conda.yml b/src/eda/conda.yml
index 2411369..6347359 100644
--- a/src/eda/conda.yml
+++ b/src/eda/conda.yml
@@ -3,11 +3,11 @@ channels:
   - conda-forge
   - defaults
 dependencies:
-  - jupyterlab=3.0.12
+  - jupyter=1.0.0 #jupyterlab=3.0.12
   - seaborn=0.11.1
   - pandas=1.2.3
   - pip=20.3.3
-  - pandas-profiling=2.11.0
+  - pandas-profiling=3.6.1 #3.1.0 #2.11.0
   - pyarrow=2.0
   - pip:
       - wandb==0.10.31
\ No newline at end of file
diff --git a/src/train_random_forest/conda.yml b/src/train_random_forest/conda.yml
index c481bc6..74e5535 100644
--- a/src/train_random_forest/conda.yml
+++ b/src/train_random_forest/conda.yml
@@ -5,9 +5,9 @@ channels:
 dependencies:
   - pandas=1.1.4
   - pip=20.3.3
-  - mlflow=1.14.1
+  - mlflow=2.2.2 #1.14.1
   - scikit-learn=0.24.1
-  - matplotlib=3.2.2
   - pillow=8.1.2
   - pip:
       - wandb==0.10.21
+      - matplotlib==3.2.2
diff --git a/src/train_random_forest/run.py b/src/train_random_forest/run.py
index d8f37d4..eeae131 100644
--- a/src/train_random_forest/run.py
+++ b/src/train_random_forest/run.py
@@ -54,7 +54,9 @@ def go(args):
     ######################################
     # Use run.use_artifact(...).file() to get the train and validation artifact (args.trainval_artifact)
     # and save the returned path in train_local_pat
-    trainval_local_path = # YOUR CODE HERE
+
+    logger.info("Downloading and reading trainval artifact")
+    trainval_local_path = run.use_artifact(args.trainval_artifact).file()
     ######################################
 
     X = pd.read_csv(trainval_local_path)
@@ -76,6 +78,7 @@ def go(args):
     ######################################
     # Fit the pipeline sk_pipe by calling the .fit method on X_train and y_train
     # YOUR CODE HERE
+    sk_pipe.fit(X_train, y_train)
     ######################################
 
     # Compute r2 and MAE
@@ -94,10 +97,21 @@ def go(args):
     if os.path.exists("random_forest_dir"):
         shutil.rmtree("random_forest_dir")
 
+        #export_path = os.path.join(temp_dir, "model_export") #femi
+
     ######################################
     # Save the sk_pipe pipeline as a mlflow.sklearn model in the directory "random_forest_dir"
     # HINT: use mlflow.sklearn.save_model
     # YOUR CODE HERE
+
+    mlflow.sklearn.save_model(
+            sk_pipe,
+            "random_forest_dir", #export_path,
+            serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,
+            #signature=signature,
+            #input_example=X_val.iloc[:2],
+        )
+
     ######################################
 
     ######################################
@@ -107,6 +121,19 @@ def go(args):
     # you just created to add the "random_forest_dir" directory to the artifact, and finally use
     # run.log_artifact to log the artifact to the run
     # YOUR CODE HERE
+
+
+    artifact = wandb.Artifact(
+        args.output_artifact,
+        type="model_export",
+        description="Random Forest model export",
+        metadata = rf_config
+    )
+    artifact.add_dir("random_forest_dir")
+
+    run.log_artifact(artifact)
+
+
     ######################################
 
     # Plot feature importance
@@ -117,6 +144,9 @@ def go(args):
     run.summary['r2'] = r_squared
     # Now log the variable "mae" under the key "mae".
     # YOUR CODE HERE
+
+    run.summary['mae'] = mae
+
     ######################################
 
     # Upload to W&B the feture importance visualization
@@ -158,7 +188,9 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
     # Build a pipeline with two steps:
     # 1 - A SimpleImputer(strategy="most_frequent") to impute missing values
     # 2 - A OneHotEncoder() step to encode the variable
-    non_ordinal_categorical_preproc = # YOUR CODE HERE
+    non_ordinal_categorical_preproc = make_pipeline(
+        SimpleImputer(strategy="most_frequent"), OneHotEncoder()
+            )# YOUR CODE HERE
     ######################################
 
     # Let's impute the numerical columns to make sure we can handle missing values
@@ -217,7 +249,12 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
     # ColumnTransformer instance that we saved in the `preprocessor` variable, and a step called "random_forest"
     # with the random forest instance that we just saved in the `random_forest` variable.
     # HINT: Use the explicit Pipeline constructor so you can assign the names to the steps, do not use make_pipeline
-    sk_pipe = # YOUR CODE HERE
+    sk_pipe = Pipeline(
+        steps=[
+            ("preprocessor", preprocessor),
+            ("random_forest", random_Forest),
+        ]
+    )# YOUR CODE HERE
 
     return sk_pipe, processed_features
 
